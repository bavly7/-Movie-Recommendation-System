{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1187,"sourceType":"datasetVersion","datasetId":626}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bavlywaleed/movie-recommendation-system?scriptVersionId=254958888\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:08:48.27029Z","iopub.execute_input":"2025-08-07T15:08:48.270555Z","iopub.status.idle":"2025-08-07T15:08:50.003086Z","shell.execute_reply.started":"2025-08-07T15:08:48.270534Z","shell.execute_reply":"2025-08-07T15:08:50.002291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MovieLens 100K recommender: user-based CF, item-based CF, SVD\n# Requirements: pandas, numpy, sklearn\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nimport random\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\nrandom.seed(RANDOM_STATE)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:23:39.658262Z","iopub.execute_input":"2025-08-08T12:23:39.658579Z","iopub.status.idle":"2025-08-08T12:23:39.683178Z","shell.execute_reply.started":"2025-08-08T12:23:39.658555Z","shell.execute_reply":"2025-08-08T12:23:39.681876Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**u.data** ‚Äî Contains the actual ratings data.\n\n**u.item** ‚Äî To get movie names and genres .\n\n**u1.base**, ***u1.test***, ..., **u5.base**, **u5.test**                 ‚ùå Optional (for now)\nThese are for cross-validation. Use if you want to test your model thoroughly with built-in 5-fold splits. Not required for basic modeling.","metadata":{}},{"cell_type":"markdown","source":"## 1. `load_and_prepare_data`\n**What it does:**\n- Reads the ratings file (`u.data`) and movie metadata file (`u.item`).\n- Merges them so each rating has the corresponding movie title.\n- Returns both the ratings table and the movie titles table.\n\n**Purpose in recommender systems:**\n- You need both **who rated what** (user‚Äìitem interactions) and **what each item is** (titles).\n- Without merging, the system would only output IDs instead of readable recommendations.","metadata":{}},{"cell_type":"code","source":"# ---------- Data loading ----------\n\ndef load_and_prepare_data(ratings_path, items_path):\n    ratings = pd.read_csv(ratings_path, sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n    movies = pd.read_csv(items_path, sep='|', names=list(range(24)), encoding='latin-1', header=None, index_col=False)\n    # first two columns are movie id and title\n    movies = movies[[0, 1]]\n    movies.columns = ['movie_id', 'title']\n    ratings = ratings.merge(movies, on='movie_id')\n    return ratings, movies\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. `leave_one_out_split`\n**What it does:**\n- For each user, randomly removes one movie they rated to serve as a **test item**.\n- The rest of the ratings remain in the **training set**.\n\n**Purpose:**\n- A realistic evaluation method.\n- The recommender tries to predict the held-out movie as part of its top recommendations.\n- Measures if the system can ‚Äúrecover‚Äù an item the user actually liked.","metadata":{}},{"cell_type":"code","source":"# ---------- Train-test split (leave-one-out per user) ----------\n\ndef leave_one_out_split(ratings_df, seed=RANDOM_STATE):\n    # For each user: pick one rated movie as test, the rest as train.\n    users = ratings_df['user_id'].unique()\n    train_rows = []\n    test_rows = []\n    grouped = ratings_df.groupby('user_id')\n    for user, group in grouped:\n        if len(group) < 2:\n            # keep all in train if user has only 1 rating\n            train_rows.extend(group.index.tolist())\n            continue\n        test_idx = group.sample(n=1, random_state=seed).index[0]\n        test_rows.append(test_idx)\n        train_rows.extend([i for i in group.index if i != test_idx])\n    train = ratings_df.loc[train_rows].reset_index(drop=True)\n    test = ratings_df.loc[test_rows].reset_index(drop=True)\n    return train, test\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create the User-Item Matrix\n\n# üí° Explanation:\n\n- Rows: users\n\n- Columns: movie titles\n\n- Values: ratings (1 to 5)\n\n- NaN means the user hasn‚Äôt rated that movie.\n\n```python \n\n table = pd.pivot_table(df, values='D', index=['A', 'B'],\n                       columns=['C'], aggfunc=\"sum\")\ntable\nC        large  small\nA   B\nbar one    4.0    5.0\n    two    7.0    6.0\nfoo one    4.0    1.0\n    two    NaN    6.0\n","metadata":{}},{"cell_type":"code","source":"\n# ---------- Utility: pivot to matrix ----------\n\ndef build_user_item_matrix(ratings_df):\n    return ratings_df.pivot_table(index='user_id', columns='title', values='rating')\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. `compute_user_similarity_mean_center`\n**What it does:**\n- Calculates the **average rating per user**.\n- Creates a **mean-centered matrix**: subtract each user‚Äôs average from their ratings.\n- Computes **cosine similarity** between all users using the centered matrix.\n\n**Purpose:**\n- Raw ratings are biased (some users always rate high, some low).\n- Mean-centering removes that bias so similarity reflects **taste patterns**, not generosity.\n- Cosine similarity tells us ‚Äúhow alike‚Äù two users are in terms of preferences.\n\n\n## 5. `predict_for_user_user_based`\n**What it does:**\n- For a target user:\n  - Finds their top-K most similar users (**neighbors**).\n  - Uses those neighbors‚Äô ratings to predict scores for movies the target user hasn‚Äôt seen.\n  - Adds the user‚Äôs average rating back to get final predictions.\n\n**Purpose:**\n- **User-based collaborative filtering**.\n- Idea: ‚ÄúIf users similar to you liked a movie, you probably will too.‚Äù","metadata":{}},{"cell_type":"code","source":"# ---------- User-based CF (mean-centering + top-K neighbors) ----------\n\ndef compute_user_similarity_mean_center(matrix):\n    # matrix: DataFrame user x item with NaNs\n    # mean-center rows (user): subtract user's mean over observed ratings\n    user_means = matrix.mean(axis=1)\n    centered = matrix.sub(user_means, axis=0).fillna(0)\n    sim = cosine_similarity(centered)\n    sim_df = pd.DataFrame(sim, index=matrix.index, columns=matrix.index)\n    return sim_df, user_means, centered\n\n\ndef predict_for_user_user_based(user_id, train_matrix, user_sim_df, user_means, k=30, min_sim=1e-9):\n    # train_matrix: user x item with NaNs\n    # user_sim_df: user-user similarity\n    # returns Series of predicted ratings for all items\n    if user_id not in train_matrix.index:\n        return pd.Series(dtype=float)\n    sims = user_sim_df.loc[user_id].copy()\n    # remove self\n    sims.loc[user_id] = 0\n    # pick top-k neighbors\n    top_neighbors = sims.abs().sort_values(ascending=False).head(k)\n    neighbor_ids = top_neighbors.index[top_neighbors != 0]\n    # ratings (filled 0 for unrated after centering was used in sim computation)\n    # We will compute using original train_matrix but use neighbors' mean-centered values\n    # Get neighbor mean-centered ratings\n    neighbor_centered = train_centered.loc[neighbor_ids]\n    # Weighted sum\n    weights = top_neighbors.loc[neighbor_ids]\n    # To predict for each item: predicted = user_mean + sum(weights * neighbor_centered[item]) / sum(|weights|)\n    denom = weights.abs().sum()\n    if denom < min_sim:\n        denom = min_sim\n    weighted = neighbor_centered.T.dot(weights)\n    preds = user_means.loc[user_id] + (weighted / denom)\n    preds = preds.sort_values(ascending=False)\n    return preds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. `compute_item_similarity`\n**What it does:**\n- Calculates the **average rating per movie**.\n- Creates a mean-centered matrix (centered by **movie**, not user).\n- Computes **cosine similarity** between all movies.\n\n**Purpose:**\n- Basis of **item-based collaborative filtering**.\n- Finds **similar movies** instead of similar users.\n- Example: If you liked ‚ÄúToy Story‚Äù and it‚Äôs similar to ‚ÄúA Bug‚Äôs Life,‚Äù you might like that too.\n\n---\n\n## 7. `predict_for_user_item_based`\n**What it does:**\n- For a target user:\n  - Looks at the movies they‚Äôve rated.\n  - Finds other movies similar to those.\n  - Predicts scores based on similarity weights.\n\n**Purpose:**\n- **Item-based CF** can be more stable when user data is sparse.\n- Often faster in production because movie similarities don‚Äôt change as often as user similarities.","metadata":{}},{"cell_type":"code","source":"# ---------- Item-based CF (mean-center by item) ----------\n\ndef compute_item_similarity(matrix):\n    # center by item (column mean), compute cosine similarity between items\n    item_means = matrix.mean(axis=0)\n    centered = matrix.sub(item_means, axis=1).fillna(0)\n    sim = cosine_similarity(centered.T)\n    sim_df = pd.DataFrame(sim, index=matrix.columns, columns=matrix.columns)\n    return sim_df, item_means, centered\n\n\ndef predict_for_user_item_based(user_id, train_matrix, item_sim_df, item_means, k=30):\n    # For each item j not rated by user: predict using user's ratings and item similarity\n    if user_id not in train_matrix.index:\n        return pd.Series(dtype=float)\n    user_ratings = train_matrix.loc[user_id]\n    rated = user_ratings[user_ratings.notna()]\n    candidates = train_matrix.columns.difference(rated.index)\n    preds = {}\n    for item in candidates:\n        sims = item_sim_df.loc[item, rated.index]\n        if sims.abs().sum() == 0:\n            continue\n        numer = (sims * (rated - item_means[rated.index])).sum()\n        denom = sims.abs().sum()\n        pred = item_means[item] + numer / denom\n        preds[item] = pred\n    preds = pd.Series(preds).sort_values(ascending=False)\n    return preds\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. `svd_recommender`\n**What it does:**\n- Mean-centers by user.\n- Uses **Truncated Singular Value Decomposition (SVD)** to factorize the matrix into latent factors.\n- Reconstructs predicted ratings for all user‚Äìmovie pairs.\n\n**Purpose:**\n- Matrix factorization captures hidden patterns, e.g., ‚ÄúSci-Fi lovers‚Äù or ‚ÄúRomance avoiders‚Äù.\n- Handles sparsity better and often yields better recommendations than raw similarity.","metadata":{}},{"cell_type":"code","source":"# ---------- SVD-based recommender (TruncatedSVD) ----------\n\ndef svd_recommender(train_matrix, n_components=50):\n    # center by user mean then factorize\n    user_means = train_matrix.mean(axis=1)\n    centered = train_matrix.sub(user_means, axis=0).fillna(0)\n    svd = TruncatedSVD(n_components=min(n_components, min(centered.shape)-1), random_state=RANDOM_STATE)\n    U = svd.fit_transform(centered)\n    Sigma_V = svd.components_\n    reconstructed = pd.DataFrame(U.dot(Sigma_V), index=centered.index, columns=centered.columns)\n    preds = reconstructed.add(user_means, axis=0)\n    return preds\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. `precision_at_k_for_models`\n**What it does:**\n- For each user in the test set:\n  - Generates top-K recommendations from each model.\n  - Checks if the held-out movie is in those top-K.\n  - Calculates **precision@K** (percentage of correct predictions in top-K).\n\n**Purpose:**\n- Gives a simple, interpretable metric:\n  > ‚ÄúOut of the top-K recommendations, how many are actually relevant?‚Äù\n- Higher precision means better targeting of liked movies.","metadata":{}},{"cell_type":"code","source":"# ---------- Evaluation: precision@K (using the held-out test item) ----------\n\ndef precision_at_k_for_models(train_matrix, test_df, user_sim_df=None, user_means=None,\n                              item_sim_df=None, item_means=None, svd_preds=None, k=5):\n    users = test_df['user_id'].unique()\n    results = {'user_cf': [], 'item_cf': [], 'svd': []}\n    for user in users:\n        held_title = test_df.loc[test_df['user_id'] == user, 'title'].values[0]\n        # user-based\n        if user_sim_df is not None:\n            preds_user = predict_for_user_user_based(user, train_matrix, user_sim_df, user_means, k=50)\n            topk = preds_user.index[:k].tolist()\n            results['user_cf'].append(1 if held_title in topk else 0)\n        # item-based\n        if item_sim_df is not None:\n            preds_item = predict_for_user_item_based(user, train_matrix, item_sim_df, item_means, k=50)\n            topk = preds_item.index[:k].tolist()\n            results['item_cf'].append(1 if held_title in topk else 0)\n        # svd\n        if svd_preds is not None:\n            if user in svd_preds.index:\n                topk = svd_preds.loc[user].sort_values(ascending=False).index[:k].tolist()\n                results['svd'].append(1 if held_title in topk else 0)\n            else:\n                results['svd'].append(0)\n    # average precision\n    return {model: np.mean(vals) if len(vals)>0 else np.nan for model, vals in results.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10. `Run Blocks`","metadata":{}},{"cell_type":"code","source":"\n   # Adjust these paths to your environment\nRATINGS_PATH = '/kaggle/input/movielens-100k-dataset/ml-100k/u.data'\nITEMS_PATH = '/kaggle/input/movielens-100k-dataset/ml-100k/u.item'\n\nprint('Loading data')\nratings, movies = load_and_prepare_data(RATINGS_PATH, ITEMS_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:24:05.235714Z","iopub.execute_input":"2025-08-08T12:24:05.236571Z","iopub.status.idle":"2025-08-08T12:24:05.307934Z","shell.execute_reply.started":"2025-08-08T12:24:05.236528Z","shell.execute_reply":"2025-08-08T12:24:05.307088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint('Creating train/test split (leave-one-out)')\ntrain, test = leave_one_out_split(ratings)\n\ntrain_matrix = build_user_item_matrix(train)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:24:21.004736Z","iopub.execute_input":"2025-08-08T12:24:21.005109Z","iopub.status.idle":"2025-08-08T12:24:21.540487Z","shell.execute_reply.started":"2025-08-08T12:24:21.005069Z","shell.execute_reply":"2025-08-08T12:24:21.539567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Computing user similarity (mean-centered)')\nuser_sim_df, user_means, train_centered = compute_user_similarity_mean_center(train_matrix)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:24:57.152413Z","iopub.execute_input":"2025-08-08T12:24:57.152727Z","iopub.status.idle":"2025-08-08T12:24:57.239493Z","shell.execute_reply.started":"2025-08-08T12:24:57.152701Z","shell.execute_reply":"2025-08-08T12:24:57.238548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    # store train_centered globally used by predict function\nglobal train_centered\ntrain_centered = train_centered\n\nprint('Computing item similarity (mean-centered)')\nitem_sim_df, item_means, item_centered = compute_item_similarity(train_matrix)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:25:12.862402Z","iopub.execute_input":"2025-08-08T12:25:12.86273Z","iopub.status.idle":"2025-08-08T12:25:12.958144Z","shell.execute_reply.started":"2025-08-08T12:25:12.8627Z","shell.execute_reply":"2025-08-08T12:25:12.957017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Training SVD recommender')\nsvd_preds = svd_recommender(train_matrix, n_components=50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:25:22.957388Z","iopub.execute_input":"2025-08-08T12:25:22.957658Z","iopub.status.idle":"2025-08-08T12:25:23.224451Z","shell.execute_reply.started":"2025-08-08T12:25:22.957638Z","shell.execute_reply":"2025-08-08T12:25:23.2237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint('Evaluating models using precision@5')\nscores = precision_at_k_for_models(train_matrix, test, user_sim_df=user_sim_df,\n                                      user_means=user_means, item_sim_df=item_sim_df,\n                                      item_means=item_means, svd_preds=svd_preds, k=5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:25:31.969661Z","iopub.execute_input":"2025-08-08T12:25:31.970028Z","iopub.status.idle":"2025-08-08T12:42:40.090015Z","shell.execute_reply.started":"2025-08-08T12:25:31.970002Z","shell.execute_reply":"2025-08-08T12:42:40.089142Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üìä Precision@5 Results Interpretation\n\nThe results below show the **Precision@5** for each model:\n\n- **User-based CF**: `0.0350` ‚Üí About **3.5%** of the top-5 recommendations are relevant.  \n- **Item-based CF**: `0.0053` ‚Üí Very low (~0.5% relevant).  \n- **SVD**: `0.0223` ‚Üí Slightly better than item-based, but still low.\n\nüí° **Is this good?**  \nNot really ‚Äî these numbers are far below typical benchmarks.  \nFor many recommender tasks, **Precision@5** of `0.15‚Äì0.30` is considered decent.  \nOur results mean that, on average, the user gets **less than 1 relevant item** in the top-5 list.\n\n‚öô **Possible future improvements:**\n- Use better similarity measures (e.g., adjusted cosine, Pearson).\n- Tune the number of neighbors `K`.\n- Normalize ratings before similarity calculation.\n- Try hybrid models (mix CF with popularity-based or content-based).\n- Increase dataset density or add more features.\n","metadata":{}},{"cell_type":"code","source":"\nprint('\\nPrecision@5 (averaged over users):')\nfor model, sc in scores.items():\n    print(f'{model}: {sc:.4f}')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:43:01.079846Z","iopub.execute_input":"2025-08-08T12:43:01.080669Z","iopub.status.idle":"2025-08-08T12:43:01.085515Z","shell.execute_reply.started":"2025-08-08T12:43:01.080643Z","shell.execute_reply":"2025-08-08T12:43:01.084631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example: get top-5 recommendations for a target user from each model\ntarget_user = 1\nprint(f\"\\nTop-5 recommendations for user {target_user} (USER-BASED):\")\nuser_preds = predict_for_user_user_based(target_user, train_matrix, user_sim_df, user_means, k=50)\nprint(user_preds.head(5))\n\nprint(f\"\\nTop-5 recommendations for user {target_user} (ITEM-BASED):\")\nitem_preds = predict_for_user_item_based(target_user, train_matrix, item_sim_df, item_means, k=50)\nprint(item_preds.head(5))\n\nprint(f\"\\nTop-5 recommendations for user {target_user} (SVD):\")\nif target_user in svd_preds.index:\n    print(svd_preds.loc[target_user].sort_values(ascending=False).head(5))\nelse:\n    print('No SVD predictions for this user')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:44:31.088889Z","iopub.execute_input":"2025-08-08T12:44:31.08923Z","iopub.status.idle":"2025-08-08T12:44:32.215054Z","shell.execute_reply.started":"2025-08-08T12:44:31.089205Z","shell.execute_reply":"2025-08-08T12:44:32.214055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}